# -*- coding: utf-8 -*-
"""News_NLP_Sarah5.2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Wa312hfwmjdjBy9uOJw_k-9QR1sB1SDf

<h1><center>Profil Dicoding</center></h1><hr>
<p> Nama  : Sarah Salsabila </p>
<p> Email : m314v4331@dicoding.org</p>
<p> Alamat: Karawang , Jawabarat</p>
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import re
df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/dataset/True.csv')

df.head()

df['title'] = df['title'].map(lambda x: re.sub(r'\W+', ' ', x))

df.shape

df.isnull().sum()

df['subject'].value_counts()

jenis = pd.get_dummies(df.subject)
df_baru = pd.concat([df, jenis], axis=1)
df_baru = df_baru.drop(columns='subject')
df_baru.head()

df_baru = df_baru.drop(columns=['text', 'date'])
df_baru.head()

tittle = df_baru['title'].values
label = df_baru[['politicsNews', 'worldnews']].values

from sklearn.model_selection import train_test_split
tittle_latih, tittle_test, label_latih, label_test = train_test_split(tittle, label, test_size=0.2)

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
 
tokenizer = Tokenizer(num_words=5000, oov_token='x')
tokenizer.fit_on_texts(tittle_latih) 
tokenizer.fit_on_texts(tittle_test)
 
sekuens_latih = tokenizer.texts_to_sequences(tittle_latih)
sekuens_test = tokenizer.texts_to_sequences(tittle_test)
 
padded_latih = pad_sequences(sekuens_latih) 
padded_test = pad_sequences(sekuens_test)

import tensorflow as tf
model = tf.keras.Sequential([
    tf.keras.layers.Embedding(input_dim=5000, output_dim=16),
    tf.keras.layers.LSTM(64),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.1),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(2, activation='softmax')
])

model.compile(
    loss='categorical_crossentropy',
    optimizer='adam',
    metrics=['accuracy'])

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy')>0.9 and logs.get('val_accuracy')>0.9):
      print("Akurasi train dan validasi yang didapat telah mencapai nilai > 90%!")
      self.model.stop_training = True
callbacks = myCallback()

num_epochs = 10
history = model.fit(padded_latih, label_latih, 
                    epochs=num_epochs, 
                    validation_data=(padded_test, label_test), 
                    verbose=2)

df_baru.plot.hist(bins=12,alpha=0.5)

# Commented out IPython magic to ensure Python compatibility.
from google.colab import files
from keras.preprocessing import image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline

plt.plot(history.history['accuracy'], label='Training Accuracy', color='blue')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='red')
plt.title('Accuracy Training & Validation')
plt.ylabel('Value')
plt.xlabel('Epoch')
plt.legend(loc="lower right")
plt.show()

plt.plot(history.history['loss'], label='Training Loss', color='blue')
plt.plot(history.history['val_loss'], label='Validation Loss', color = 'red')
plt.title('Loss Training & Validation')
plt.ylabel('Value')
plt.xlabel('Epoch')
plt.legend(loc="lower right")
plt.show()